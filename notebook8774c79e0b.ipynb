{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing libraries for data analysis and data visulisation\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n#importing libraries for calling files \nimport os\n\n# Importing Deep Learning Libraries\n\nfrom keras.preprocessing.image import load_img, img_to_array #model will not take the image it will take array form \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D # important layers which are required to made the CNN model \nfrom keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-03T05:01:07.416677Z","iopub.execute_input":"2022-04-03T05:01:07.416991Z","iopub.status.idle":"2022-04-03T05:01:14.465477Z","shell.execute_reply.started":"2022-04-03T05:01:07.416912Z","shell.execute_reply":"2022-04-03T05:01:14.464604Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Displaying Images","metadata":{}},{"cell_type":"code","source":"picture_size = 48 # standarised the size of each picture\nfolder_path = \"../input/face-expression-recognition-dataset/images/\"","metadata":{"execution":{"iopub.status.busy":"2022-04-03T05:16:43.986522Z","iopub.execute_input":"2022-04-03T05:16:43.987231Z","iopub.status.idle":"2022-04-03T05:16:43.991548Z","shell.execute_reply.started":"2022-04-03T05:16:43.987195Z","shell.execute_reply":"2022-04-03T05:16:43.990371Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Ploting the images of disgusting faces","metadata":{}},{"cell_type":"code","source":"expression = 'disgust'\nplt.style.use('dark_background')\nplt.figure(figsize= (12,12))\nfor i in range(1, 10, 1):\n    plt.subplot(3,3,i)\n    img = load_img(folder_path+\"train/\"+expression+\"/\"+\n                  os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n    plt.imshow(img)   \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T05:18:50.446878Z","iopub.execute_input":"2022-04-03T05:18:50.447298Z","iopub.status.idle":"2022-04-03T05:18:51.397982Z","shell.execute_reply.started":"2022-04-03T05:18:50.447259Z","shell.execute_reply":"2022-04-03T05:18:51.397433Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Making Training and Validating the data","metadata":{}},{"cell_type":"code","source":"batch_size  = 128 #signifies that in 1 iteration it should take 128 running examples\n\ndatagen_train  = ImageDataGenerator()\ndatagen_val = ImageDataGenerator()\n\ntrain_set = datagen_train.flow_from_directory(folder_path+\"train\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',#for 7 different categories of output\n                                              shuffle=True)\n\n#validation set\ntest_set = datagen_val.flow_from_directory(folder_path+\"validation\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T05:20:46.815113Z","iopub.execute_input":"2022-04-03T05:20:46.815453Z","iopub.status.idle":"2022-04-03T05:21:13.358080Z","shell.execute_reply.started":"2022-04-03T05:20:46.815414Z","shell.execute_reply":"2022-04-03T05:21:13.357232Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"no_of_classes = 7\n\nmodel = Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))#64 filters and 3x3 kernal size\nmodel.add(BatchNormalization())#Batch normalization applies a transformation that maintains the mean output close to 0\nmodel.add(Activation('relu'))# activation function to increase the non-linearity in the output\nmodel.add(MaxPooling2D(pool_size = (2,2)))#extract the particular imporatant information from that area where this pool is set i.e 2x2\nmodel.add(Dropout(0.25))#to prevent over model from overfitting\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())#for converting the data into a 1-dimensional array for inputting it to the next layer\n\n#Fully connected 1st layer\nmodel.add(Dense(256))#receives input from all the neurons of previous layer\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\n\nopt = Adam(lr = 0.0001)#adam optimizer with learning rate 0.0001\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()#printing the summary of my model","metadata":{"execution":{"iopub.status.busy":"2022-04-03T05:49:06.233163Z","iopub.execute_input":"2022-04-03T05:49:06.233470Z","iopub.status.idle":"2022-04-03T05:49:06.629122Z","shell.execute_reply.started":"2022-04-03T05:49:06.233441Z","shell.execute_reply":"2022-04-03T05:49:06.626476Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Fitting the Model with Training and Validation Data ","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\"./face_emotion_model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\n#Reduce the learning rate which was initally set by us when a metric has stopped improving\nreduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\n#list containing all three parameters\ncallbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n\n#epochs defines the number times that the learning algorithm will work through the entire training dataset.\nepochs = 48\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-03T06:03:02.913848Z","iopub.execute_input":"2022-04-03T06:03:02.914088Z","iopub.status.idle":"2022-04-03T06:03:02.926342Z","shell.execute_reply.started":"2022-04-03T06:03:02.914063Z","shell.execute_reply":"2022-04-03T06:03:02.925458Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_set,\n                                steps_per_epoch=train_set.n//train_set.batch_size,\n                                epochs=epochs,\n                                validation_data = test_set,\n                                validation_steps = test_set.n//test_set.batch_size,\n                                callbacks=callbacks_list\n                                )","metadata":{"execution":{"iopub.status.busy":"2022-04-03T06:03:23.732261Z","iopub.execute_input":"2022-04-03T06:03:23.732545Z","iopub.status.idle":"2022-04-03T07:16:33.650952Z","shell.execute_reply.started":"2022-04-03T06:03:23.732517Z","shell.execute_reply":"2022-04-03T07:16:33.650421Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Plotting Accuracy & Loss","metadata":{}},{"cell_type":"code","source":"plt.style.use('dark_background')\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T07:28:51.740255Z","iopub.execute_input":"2022-04-03T07:28:51.740519Z","iopub.status.idle":"2022-04-03T07:28:52.077536Z","shell.execute_reply.started":"2022-04-03T07:28:51.740495Z","shell.execute_reply":"2022-04-03T07:28:52.076498Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}